{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "025b69a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/users/misenta/CellViT-plus-plus/cellvit/models/utils/hibou_utils.py:54: UserWarning: xFormers is disabled\n",
      "  warnings.warn(\"xFormers is disabled\")\n",
      "/scratch/users/misenta/CellViT-plus-plus/cellvit/models/utils/hibou_utils.py:60: UserWarning: xFormers is not available\n",
      "  warnings.warn(\"xFormers is not available\")\n",
      "/opt/conda/envs/tissuevit/lib/python3.10/site-packages/cupy/_environment.py:596: UserWarning: \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  CuPy may not function correctly because multiple CuPy packages are installed\n",
      "  in your environment:\n",
      "\n",
      "    cupy, cupy-cuda12x\n",
      "\n",
      "  Follow these steps to resolve this issue:\n",
      "\n",
      "    1. For all packages listed above, run the following command to remove all\n",
      "       existing CuPy installations:\n",
      "\n",
      "         $ pip uninstall <package_name>\n",
      "\n",
      "      If you previously installed CuPy via conda, also run the following:\n",
      "\n",
      "         $ conda uninstall cupy\n",
      "\n",
      "    2. Install the appropriate CuPy package.\n",
      "       Refer to the Installation Guide for detailed instructions.\n",
      "\n",
      "         https://docs.cupy.dev/en/stable/install.html\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  warnings.warn(f'''\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import types\n",
    "import importlib\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# Disable xformers to avoid GPU attention bias mismatch\n",
    "os.environ[\"XFORMERS_DISABLED\"] = \"1\"\n",
    "\n",
    "# Stub flash_attn to avoid binary import on CPU\n",
    "if 'flash_attn.flash_attn_interface' not in sys.modules:\n",
    "    flash_attn_interface = types.ModuleType('flash_attn.flash_attn_interface')\n",
    "    def flash_attn_func(*args, **kwargs):\n",
    "        raise ImportError('flash_attn disabled for this test')\n",
    "    flash_attn_interface.flash_attn_func = flash_attn_func\n",
    "    flash_attn = types.ModuleType('flash_attn')\n",
    "    flash_attn.flash_attn_interface = flash_attn_interface\n",
    "    sys.modules['flash_attn'] = flash_attn\n",
    "    sys.modules['flash_attn.flash_attn_interface'] = flash_attn_interface\n",
    "\n",
    "import cellvit.models.cell_segmentation.backbones_mmvirtues as backbones_mmvirtues\n",
    "importlib.reload(backbones_mmvirtues)\n",
    "import cellvit.models.cell_segmentation.cellvit_mmvirtues as cellvit_mmvirtues\n",
    "importlib.reload(cellvit_mmvirtues)\n",
    "from cellvit.models.cell_segmentation.cellvit_mmvirtues import CellViTMMVirtues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c967ccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_dir = Path('/scratch/mmvirtues_orion_dataset/virtues_example/mmvirtues_weights')\n",
    "mmvirtues_root = Path('/scratch/mmvirtues_orion_dataset/virtues_example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d8df8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/mmvirtues_orion_dataset/virtues_example/modules/mmvirtues/vit_layers/swiglu_ffn.py:45: UserWarning: xFormers is disabled (SwiGLU)\n",
      "  warnings.warn(\"xFormers is disabled (SwiGLU)\")\n",
      "/scratch/mmvirtues_orion_dataset/virtues_example/modules/mmvirtues/vit_layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/scratch/mmvirtues_orion_dataset/virtues_example/modules/mmvirtues/vit_layers/attention.py:29: UserWarning: xFormers is disabled (Attention)\n",
      "  warnings.warn(\"xFormers is disabled (Attention)\")\n",
      "/scratch/mmvirtues_orion_dataset/virtues_example/modules/mmvirtues/vit_layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/scratch/mmvirtues_orion_dataset/virtues_example/modules/mmvirtues/vit_layers/block.py:36: UserWarning: xFormers is disabled (Block)\n",
      "  warnings.warn(\"xFormers is disabled (Block)\")\n",
      "/scratch/mmvirtues_orion_dataset/virtues_example/modules/mmvirtues/vit_layers/block.py:41: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n",
      "\u001b[32m2025-12-16 15:33:21.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodules.mmvirtues.layers\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mUsing xformers for FlexDualVirTues\u001b[0m\n",
      "\u001b[32m2025-12-16 15:33:21.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodules.mmvirtues.flex_dual_mmvirtues\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1mUsing protein embedding: esm with shape torch.Size([213, 640])\u001b[0m\n",
      "\u001b[32m2025-12-16 15:33:21.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodules.mmvirtues.flex_dual_mmvirtues\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m117\u001b[0m - \u001b[1mUsing protein fusion type: add\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])\n"
     ]
    }
   ],
   "source": [
    "model = CellViTMMVirtues(\n",
    "    mmvirtues_weights_path=weights_dir,\n",
    "    mmvirtues_root=mmvirtues_root,\n",
    "    num_nuclei_classes=6,\n",
    "    num_tissue_classes=19,\n",
    "    regression_loss=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1d5f805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CellViTMMVirtues(\n",
       "  (encoder): MMVirtuesEncoder(\n",
       "    (model): DinoVisionTransformer(\n",
       "      (he_embed_layer): PatchEmbed(\n",
       "        (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
       "        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (mx_embed_layer): FlexDualVirTuesEncoder(\n",
       "        (protein_encoder): Linear(in_features=640, out_features=1024, bias=True)\n",
       "        (he_patch_encoder): Linear(in_features=588, out_features=1024, bias=True)\n",
       "        (multiplex_patch_encoder): Linear(in_features=196, out_features=1024, bias=True)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder): ModuleList(\n",
       "          (0): MarkerAttentionEncoderBlock(\n",
       "            (encoder_layer): TransformerEncoder(\n",
       "              (layers): ModuleList(\n",
       "                (0-1): 2 x TransformerEncoderBlock(\n",
       "                  (multi_head_attention): MHAwithPosEmb(\n",
       "                    (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                    (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                    (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                    (W_o): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  )\n",
       "                  (feedforward): Sequential(\n",
       "                    (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "                    (1): GELU(approximate='none')\n",
       "                    (2): Dropout(p=0.0, inplace=False)\n",
       "                    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "                  )\n",
       "                  (layernorm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (layernorm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (blocks): ModuleList(\n",
       "        (0-23): 24 x NestedTensorBlock(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MemEffAttention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLUFFNFused(\n",
       "            (w12): Linear(in_features=1024, out_features=5472, bias=True)\n",
       "            (w3): Linear(in_features=2736, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (head): Identity()\n",
       "    )\n",
       "    (head): Linear(in_features=1024, out_features=19, bias=True)\n",
       "  )\n",
       "  (decoder0): Sequential(\n",
       "    (0): Conv2DBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Conv2DBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder1): Sequential(\n",
       "    (0): Deconv2DBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Deconv2DBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Deconv2DBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder2): Sequential(\n",
       "    (0): Deconv2DBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Deconv2DBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder3): Sequential(\n",
       "    (0): Deconv2DBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (nuclei_binary_map_decoder): Sequential(\n",
       "    (bottleneck_upsampler): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (decoder3_upsampler): Sequential(\n",
       "      (0): Conv2DBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Conv2DBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Conv2DBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (decoder2_upsampler): Sequential(\n",
       "      (0): Conv2DBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Conv2DBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (decoder1_upsampler): Sequential(\n",
       "      (0): Conv2DBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Conv2DBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (decoder0_header): Sequential(\n",
       "      (0): Conv2DBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Conv2DBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (hv_map_decoder): Sequential(\n",
       "    (bottleneck_upsampler): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (decoder3_upsampler): Sequential(\n",
       "      (0): Conv2DBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Conv2DBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Conv2DBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (decoder2_upsampler): Sequential(\n",
       "      (0): Conv2DBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Conv2DBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (decoder1_upsampler): Sequential(\n",
       "      (0): Conv2DBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Conv2DBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (decoder0_header): Sequential(\n",
       "      (0): Conv2DBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Conv2DBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (nuclei_type_maps_decoder): Sequential(\n",
       "    (bottleneck_upsampler): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (decoder3_upsampler): Sequential(\n",
       "      (0): Conv2DBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Conv2DBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Conv2DBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (decoder2_upsampler): Sequential(\n",
       "      (0): Conv2DBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Conv2DBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (decoder1_upsampler): Sequential(\n",
       "      (0): Conv2DBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Conv2DBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (decoder0_header): Sequential(\n",
       "      (0): Conv2DBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Conv2DBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Conv2d(64, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc30ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad92407a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tissue logits: torch.Size([1, 19])\n",
      "intermediate token shapes: [torch.Size([1, 257, 1024]), torch.Size([1, 257, 1024]), torch.Size([1, 257, 1024]), torch.Size([1, 257, 1024])]\n",
      "{'tissue_types': torch.Size([1, 19]), 'nuclei_binary_map': torch.Size([1, 2, 256, 256]), 'hv_map': torch.Size([1, 2, 256, 256]), 'nuclei_type_map': torch.Size([1, 6, 256, 256])}\n",
      "marker_embeddings_dir: /scratch/mmvirtues_orion_dataset/virtues_example/marker_embeddings_symlink\n"
     ]
    }
   ],
   "source": [
    "# Debug: run encoder only first to confirm token shapes\n",
    "with torch.no_grad():\n",
    "    logits, _, z = model.encoder(x)\n",
    "print(\"tissue logits:\", logits.shape)\n",
    "print(\"intermediate token shapes:\", [t.shape for t in z])\n",
    "\n",
    "# Full forward (segmentation heads)\n",
    "with torch.no_grad():\n",
    "    out = model(x)\n",
    "print({k: v.shape if torch.is_tensor(v) else type(v) for k, v in out.items()})\n",
    "print(\"marker_embeddings_dir:\", model.encoder.marker_embeddings_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55702da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tissue_types': torch.Size([1, 19]), 'nuclei_binary_map': torch.Size([1, 2, 256, 256]), 'hv_map': torch.Size([1, 2, 256, 256]), 'nuclei_type_map': torch.Size([1, 6, 256, 256])}\n"
     ]
    }
   ],
   "source": [
    "print({k: v.shape if torch.is_tensor(v) else type(v) for k, v in out.items()})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tissuevit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
